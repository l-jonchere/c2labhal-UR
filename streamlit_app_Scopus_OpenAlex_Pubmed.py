import os
import streamlit as st
import pandas as pd
import io
import requests
import json
from metapub import PubMedFetcher
import regex as re
from unidecode import unidecode
import unicodedata
from difflib import get_close_matches
from langdetect import detect
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor  
from utils import (
    get_scopus_data, get_openalex_data, get_pubmed_data, convert_to_dataframe,
    clean_doi, HalCollImporter, merge_rows_with_sources, get_authors_from_crossref,
    check_df, enrich_w_upw_parallel, add_permissions_parallel, deduce_todo,
    normalise, normalize_name, get_initial_form
)

# Configurer tqdm pour pandas
tqdm.pandas()

class ScopusOpenAlexPubmedApp:
    def __init__(self):
        self.prefix = "app1_"  # PrÃ©fixe unique pour cette application
        self.collection_a_chercher = ""
        self.openalex_institution_id = ""
        self.pubmed_id = ""
        self.pubmed_api_key = ""
        self.scopus_lab_id = ""
        self.scopus_api_key = ""
        self.start_year = 2020
        self.end_year = 2025
        self.fetch_authors = False
        self.compare_authors = False
        self.uploaded_authors_file = None
        self.progress_bar = None
        self.progress_text = None
        self.scopus_df = pd.DataFrame()
        self.openalex_df = pd.DataFrame()
        self.pubmed_df = pd.DataFrame()
        self.combined_df = pd.DataFrame()
        self.merged_data = pd.DataFrame()


    def run(self): # La mÃ©thode run est maintenant Ã  l'intÃ©rieur de la classe
        st.title("ðŸ¥Ž c2LabHAL")
        st.subheader("Comparez les publications d'un labo dans Scopus, OpenAlex et Pubmed avec sa collection HAL")

        self.collection_a_chercher = st.text_input(
            "Collection HAL",
            value="",
            key=self.prefix + "collection_hal",  # PrÃ©fixe ajoutÃ©
            help="Saisissez le nom de la collection HAL du laboratoire, par exemple MIP"
        )

        self.openalex_institution_id = st.text_input(
            "Identifiant OpenAlex du labo",
            key=self.prefix + "openalex_id",  # PrÃ©fixe ajoutÃ©
            help="Saisissez l'identifiant du labo dans OpenAlex, par exemple i4392021216"
        )

        col1, col2 = st.columns(2)
        with col1:
            self.pubmed_id = st.text_input(
                "RequÃªte PubMed",
                key=self.prefix + "pubmed_query",  # PrÃ©fixe ajoutÃ©
                help="Saisissez la requÃªte Pubmed qui rassemble le mieux les publications du labo..."
            )
        with col2:
            self.pubmed_api_key = st.text_input(
                "ClÃ© API Pubmed",
                key=self.prefix + "pubmed_api_key",  # PrÃ©fixe ajoutÃ©
                help="Pour obtenir une clÃ© API, connectez vous sur Pubmed..."
            )

        col1, col2 = st.columns(2)
        with col1:
            self.scopus_lab_id = st.text_input(
                "Identifiant Scopus du labo",
                key=self.prefix + "scopus_lab_id",  # PrÃ©fixe ajoutÃ©
                help="Saisissez le Scopus Affiliation Identifier du laboratoire..."
            )
        with col2:
            self.scopus_api_key = st.text_input(
                "ClÃ© API Scopus",
                key=self.prefix + "scopus_api_key",  # PrÃ©fixe ajoutÃ©
                help="Pour obtenir une clÃ© API : https://dev.elsevier.com/..."
            )

        col1, col2 = st.columns(2)
        with col1:
            self.start_year = st.number_input(
                "AnnÃ©e de dÃ©but",
                min_value=1900,
                max_value=2100,
                value=2020,
                key=self.prefix + "start_year"  # PrÃ©fixe ajoutÃ©
            )
        with col2:
            self.end_year = st.number_input(
                "AnnÃ©e de fin",
                min_value=1900,
                max_value=2100,
                value=2025,
                key=self.prefix + "end_year"  # PrÃ©fixe ajoutÃ©
            )

        self.fetch_authors = st.checkbox(
            "ðŸ§‘â€ðŸ”¬ RÃ©cupÃ©rer les auteurs sur Crossref",
            key=self.prefix + "fetch_authors"  # PrÃ©fixe ajoutÃ©
        )

        if self.fetch_authors:
            self.compare_authors = st.checkbox(
                "ðŸ” Comparer les auteurs avec ma liste de chercheurs",
                key=self.prefix + "compare_authors"  # PrÃ©fixe ajoutÃ©
            )
            if self.compare_authors:
                self.uploaded_authors_file = st.file_uploader(
                    "ðŸ“¤ TÃ©lÃ©versez un fichier CSV avec deux colonnes : 'collection', 'prÃ©nom nom'",
                    type=["csv"],
                    key=self.prefix + "authors_file"  # PrÃ©fixe ajoutÃ©
                )

        self.progress_bar = st.progress(0)  # PrÃ©fixe ajoutÃ©
        self.progress_text = st.empty()

        if st.button("Rechercher", key=self.prefix + "rechercher"):  
            # Configurer la clÃ© API PubMed si elle est fournie
            if self.pubmed_api_key:
                os.environ['NCBI_API_KEY'] = self.pubmed_api_key

            # Initialiser des DataFrames vides
            self.scopus_df = pd.DataFrame()
            self.openalex_df = pd.DataFrame()
            self.pubmed_df = pd.DataFrame()

            # Ã‰tape 1 : RÃ©cupÃ©ration des donnÃ©es OpenAlex
            with st.spinner("OpenAlex"):
                self.progress_text.text("Ã‰tape 1 : RÃ©cupÃ©ration des donnÃ©es OpenAlex")
                self.progress_bar.progress(10)
                if self.openalex_institution_id:
                    openalex_query = f"institutions.id:{self.openalex_institution_id},publication_year:{self.start_year}-{self.end_year}"
                    openalex_data = self.get_openalex_data(openalex_query)
                    self.openalex_df = self.convert_to_dataframe(openalex_data, 'openalex')
                    self.openalex_df['Source title'] = self.openalex_df.apply(
                        lambda row: row['primary_location']['source']['display_name'] if row['primary_location'] and row['primary_location'].get('source') else None, axis=1
                    )
                    self.openalex_df['Date'] = self.openalex_df.apply(
                        lambda row: row.get('publication_date', None), axis=1
                    )
                    self.openalex_df['doi'] = self.openalex_df.apply(
                        lambda row: row.get('doi', None), axis=1
                    )
                    self.openalex_df['id'] = self.openalex_df.apply(
                        lambda row: row.get('id', None), axis=1
                    )
                    self.openalex_df['title'] = self.openalex_df.apply(
                        lambda row: row.get('title', None), axis=1
                    )
                    self.openalex_df = self.openalex_df[['source', 'title', 'doi', 'id', 'Source title', 'Date']]
                    self.openalex_df.columns = ['Data source', 'Title', 'doi', 'id', 'Source title', 'Date']
                    self.openalex_df['doi'] = self.openalex_df['doi'].apply(clean_doi)

            # Ã‰tape 2 : RÃ©cupÃ©ration des donnÃ©es PubMed
            with st.spinner("Pubmed"):
                self.progress_text.text("Ã‰tape 2 : RÃ©cupÃ©ration des donnÃ©es PubMed")
                self.progress_bar.progress(30)
                if self.pubmed_id:
                    pubmed_query = f"{self.pubmed_id} AND {self.start_year}/01/01:{self.end_year}/12/31[Date - Publication]"
                    pubmed_data = self.get_pubmed_data(pubmed_query)
                    self.pubmed_df = pd.DataFrame(pubmed_data)

            # Ã‰tape 3 : RÃ©cupÃ©ration des donnÃ©es Scopus
            with st.spinner("Scopus"):
                self.progress_text.text("Ã‰tape 3 : RÃ©cupÃ©ration des donnÃ©es Scopus")
                self.progress_bar.progress(50)
                if self.scopus_api_key and self.scopus_lab_id:
                    scopus_query = f"af-ID({self.scopus_lab_id}) AND PUBYEAR > {self.start_year - 1} AND PUBYEAR < {self.end_year + 1}"
                    scopus_data = self.get_scopus_data(self.scopus_api_key, scopus_query)
                    self.scopus_df = self.convert_to_dataframe(scopus_data, 'scopus')

                    self.scopus_df = self.scopus_df[['source', 'dc:title', 'prism:doi', 'dc:identifier', 'prism:publicationName', 'prism:coverDate']]
                    self.scopus_df.columns = ['Data source', 'Title', 'doi', 'id', 'Source title', 'Date']

            # Ã‰tape 4 : Comparaison avec HAL (si le champ "Collection HAL" n'est pas vide)
            if self.collection_a_chercher:
                with st.spinner("HAL"):
                    self.progress_text.text("Ã‰tape 4 : Comparaison avec HAL")
                    self.progress_bar.progress(70)
                    # Combiner les DataFrames
                    self.combined_df = pd.concat([self.scopus_df, self.openalex_df, self.pubmed_df], ignore_index=True)

                    # RÃ©cupÃ©rer les donnÃ©es HAL
                    coll = HalCollImporter(self.collection_a_chercher, self.start_year, self.end_year)
                    coll_df = coll.import_data()
                    coll_df['nti'] = coll_df['Titres'].apply(lambda x: normalise(x).strip())
                    self.combined_df = check_df(self.combined_df, coll_df, progress_bar=self.progress_bar, progress_text=self.progress_text)

                with st.spinner("Unpaywall"):
                    self.progress_text.text("Ã‰tape 5 : RÃ©cupÃ©ration des donnÃ©es Unpaywall")
                    self.progress_bar.progress(75)
                    self.combined_df = enrich_w_upw_parallel(self.combined_df)

                with st.spinner("OA.Works"):
                    self.progress_text.text("Ã‰tape 6 : RÃ©cupÃ©ration des permissions via OA.Works")
                    self.progress_bar.progress(85)
                    self.combined_df = add_permissions_parallel(self.combined_df)

                self.combined_df['Action'] = self.combined_df.apply(deduce_todo, axis=1)
            else:
                self.combined_df = pd.concat([self.scopus_df, self.openalex_df, self.pubmed_df], ignore_index=True)

             # Ã‰tape 7 : Fusion des lignes en double
            with st.spinner("Fusion"):
                self.progress_text.text("Ã‰tape 7 : Fusion des lignes en double")
                self.progress_bar.progress(90)
                # SÃ©parer les lignes avec et sans DOI
                with_doi = self.combined_df.dropna(subset=['doi'])
                without_doi = self.combined_df[self.combined_df['doi'].isna()]

                # Fusionner les lignes avec DOI
                merged_with_doi = with_doi.groupby('doi', as_index=False).apply(merge_rows_with_sources)

                # Combiner les lignes fusionnÃ©es avec les lignes sans DOI
                self.merged_data = pd.concat([merged_with_doi, without_doi], ignore_index=True)

               # Ã‰tape 8 : Ajout des auteurs Ã  partir de Crossref (si la case est cochÃ©e)
            if self.fetch_authors:
                with st.spinner("Recherche des auteurs Crossref"):
                    self.progress_text.text("Ã‰tape 8 : Recherche des auteurs via Crossref")
                    self.progress_bar.progress(92)
                    self.merged_data['Auteurs'] = self.merged_data['doi'].apply(lambda doi: '; '.join(get_authors_from_crossref(doi)) if doi else '')

                # Ã‰tape 9 : Comparaison avec le fichier de chercheurs
                if self.compare_authors and self.uploaded_authors_file and self.collection_a_chercher:
                    with st.spinner("Comparaison des auteurs avec le fichier"):
                        self.progress_text.text("Ã‰tape 9 : Comparaison des auteurs")
                        self.progress_bar.progress(95)

                        user_df = pd.read_csv(self.uploaded_authors_file)
                        if "collection" not in user_df.columns or user_df.columns[1] not in user_df.columns:
                            st.error("âŒ Le fichier doit contenir une colonne 'collection' et une colonne 'prÃ©nom nom'")
                        else:
                            noms_ref = user_df[user_df["collection"].str.lower() == self.collection_a_chercher.lower()].iloc[:, 1].dropna().unique().tolist()
                            chercheur_map = {normalize_name(n): n for n in noms_ref}
                            initial_map = {get_initial_form(normalize_name(n)): n for n in noms_ref}
                            all_forms = {**chercheur_map, **initial_map}

                            def detect_known_authors(auteur_str):
                                if pd.isna(auteur_str):
                                    return ""
                                auteurs = [a.strip() for a in str(auteur_str).split(';') if a.strip()]
                                noms_detectes = []
                                for a in auteurs:
                                    norm = normalize_name(a)
                                    forme = get_initial_form(norm)
                                    match = get_close_matches(norm, all_forms.keys(), n=1, cutoff=0.8) or \
                                            get_close_matches(forme, all_forms.keys(), n=1, cutoff=0.8)
                                    if match:
                                        noms_detectes.append(all_forms[match[0]])
                                return "; ".join(noms_detectes)

                            self.merged_data['Auteurs fichier'] = self.merged_data['Auteurs'].apply(detect_known_authors)

            # VÃ©rifier si merged_data n'est pas vide avant de gÃ©nÃ©rer le CSV
            if not self.merged_data.empty:
                # GÃ©nÃ©rer le CSV Ã  partir du DataFrame
                csv = self.merged_data.to_csv(index=False)

                # CrÃ©er un objet BytesIO pour stocker le CSV
                csv_bytes = io.BytesIO()
                csv_bytes.write(csv.encode('utf-8'))
                csv_bytes.seek(0)

                # Proposer le tÃ©lÃ©chargement du CSV
                st.download_button(
                    label="TÃ©lÃ©charger le CSV",
                    data=csv_bytes,
                    file_name=f"{self.collection_a_chercher}_c2LabHAL.csv",
                    mime="text/csv"
                )

                # Mettre Ã  jour la barre de progression Ã  100%
                self.progress_bar.progress(100)
                self.progress_text.text("TerminÃ© !")

        else:
            st.error("Aucune donnÃ©e Ã  exporter. Veuillez vÃ©rifier les paramÃ¨tres de recherche.")